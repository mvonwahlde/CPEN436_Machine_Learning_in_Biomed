{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cardiovascular Disease Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Problem Description\n",
    "\n",
    "The dataset used is a cardiovascular disease dataset. The data was acquired from a multispecialty hospital in India. There are 1,000 total patient examples with 12 different features for each. The purpose for the compilation of this dataset is to generate a predictive machine-learning model to detect early-stage heart disease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Biomedical Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "### 2.1 - Packages \n",
    "\n",
    "First, running the cell below will import the packages needed for this project.\n",
    "- [numpy](https://numpy.org/) is the fundamental package for scientific computing with Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) a popular platform for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tensorflow and Keras**  \n",
    "Tensorflow is a machine learning package developed by Google. In 2019, Google integrated Keras into Tensorflow and released Tensorflow 2.0. Keras is a framework developed independently by Fran√ßois Chollet that creates a simple, layer-centric interface to Tensorflow. This project will be using the Keras interface. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Dataset Desciption\n",
    "\n",
    "This dataset contains 1,000 patient examples, each with a patient ID, a classification, and the following 12 features:\n",
    "- Age: The patient's age in years\n",
    "- Gender: The patient's gender (0 - female, 1 - male)\n",
    "- Chest Pain Type: 0 - typical angina, 1 - atypical angina, 2 - non-anginal pain, 3 - asymptomatic\n",
    "- Resting Blood Pressure: The patients resting blood pressure (mmHg)\n",
    "- Serum Cholesterol: The patient's total amount of cholesterol in their blood (mg/dL)\n",
    "- Fasting Blood Sugar: 1 - greater than 120 mg/dL, 0 - not greater than 120 mg/dL\n",
    "- Resting Electrocardiogram Results: 0 - normal, 1 - having ST-T wave abnormality, 2 - showing probable or definite left ventricular hypertrophy\n",
    "- Maximum Heart Rate Achieved: The patient's max heart rate (BPM)\n",
    "- Exercise Induced Angina: 0 - no, 1 - yes\n",
    "- Old Peak ST: How low the ST segment is below the baseline\n",
    "- Slope of the Peak Exercise ST Segment: 1 - upsloping, 2 - flat, 3 - downsloping\n",
    "- Number of Major Vessels: 0, 1, 2, or 3 major vessels\n",
    "\n",
    "Each example provides a classification where a 0 indicates the absence of heart disease and a 1 indicates the presence of heart disease.\n",
    "\n",
    "There is no missing data in this dataset; however, there are many binary and nominal values that will need to be one-hot encoded. This will be discussed more later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Loading the Data\n",
    "\n",
    "Before processing, we will load the data into two variables. The first, X, is an m x n matrix that stores each patient example and the 12 corresponding features (m examples, n features). The second, y, is an m x 1 array that provides a classification for each patient example (m examples). A 0 indicates the absence of heart disease and 1 indicates the presence of heart disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    \"\"\"\n",
    "    Loads and formats data from the WDBC dataset\n",
    "\n",
    "    Args:\n",
    "    filename : relative path for the file that holds the data\n",
    "\n",
    "    Returns:\n",
    "    X : (ndarray Shape (m,n)) data, m examples by n features\n",
    "    y : (array_like Shape (m,)) outputs, 1 == heart disease present, 0 == absent\n",
    "    \"\"\"\n",
    "    # Load the data from the file\n",
    "    data = np.loadtxt(filename, dtype=str, delimiter=',')\n",
    "\n",
    "    # Store the 12 features from each example into a 2D matrix and convert the type to float\n",
    "    X = np.array(data[1:,1:13])\n",
    "    X = X.astype(float)\n",
    "\n",
    "    # Store the outputs for each example and reshape the array to (m,)\n",
    "    y = np.array(data[1:,13])\n",
    "    y = y.astype(float)\n",
    "    y = np.reshape(y, (len(y), 1))\n",
    "    \n",
    "    # Return data and outputs\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X, y = load_data(\"./data/Cardiovascular_Disease_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 View the Variables\n",
    "\n",
    "To ensure that data is loaded into the notebook correctly, it is wise to check the first element of both variables. The code below prints the first elements of the variables `X`and `y`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X is:  [ 53.    1.    2.  171.    0.    0.    1.  147.    0.    5.3   3.    3. ]\n",
      "The first element of y is:  [1.]\n"
     ]
    }
   ],
   "source": [
    "# Print the first elements of X and y\n",
    "print ('The first element of X is: ', X[0])\n",
    "print ('The first element of y is: ', y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Check the dimensions of your variables\n",
    "\n",
    "Another way to ensure that the data has been loaded correctly is to view its dimensions. Printing the shape of `X` and `y` will show the number of examples and features in the data set. The shape of `X` should be `1000, 12`, and the shape of `Y` should be `1000, 1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (1000, 12)\n",
      "The shape of y is: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of X and y\n",
    "print ('The shape of X is: ' + str(X.shape))\n",
    "print ('The shape of y is: ' + str(y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To provide the best possible data for the model, two things should be done to the data. For numerical features, z-score normalization should be applied so that some features do not have a greater weight than others. For binary and nominal features, one-hot encoding should be used to better interpret the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Z-Score Normalization Description\n",
    "\n",
    "For continuous valued features, z-score normalization will help ensure that each feature carries the same weight in the model. Z-score normalization is a method of feature scaling that involves using the mean and standard deviation of a feature to calculate the scaled version for each example. To calculate the scaled value for each example in feature j, use the following function. \n",
    "$$ x_{j, scaled} = \\frac{x_{j} - M_{j}}{\\sigma_{j}}$$\n",
    "Where $M_{j}$ is the mean of the examples in feature j, and $\\sigma_{j}$ is the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-Hot Encoding Description\n",
    "\n",
    "For features that are either binary or nominal, one-hot encoding will be used to provide the model with a better understanding of the data. Some features, such as gender, do not fit well in the model as a simple 1 or 0. The same applies to nominal features, where a 0, 1, 2, or 3 indicates different attributes of some feature. Instead, it may be wise to one-hot encode that feature. This involves splitting one feature into p different features, where p represents the number of distinct possible outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing and One-Hot Encoding Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will go through each feature and apply z-score normalization if it is numerical or apply one-hot encoding if it is binary or nominal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new variable to store each feature added\n",
    "X_new = np.empty(shape = (1000,0))\n",
    "\n",
    "# Create temporary variables to store the new columns that will be added to X_new\n",
    "tmp = np.empty(shape = (1000,1))\n",
    "tmp2 = np.empty(shape = (1000,1))\n",
    "tmp3 = np.empty(shape = (1000,1))\n",
    "tmp4 = np.empty(shape = (1000,1))\n",
    "\n",
    "# Feature 1 - Numeric\n",
    "mean = np.mean(X[:,0], axis=0)\n",
    "sigma  = np.std(X[:,0], axis=0) \n",
    "tmp = (X[:,0] - mean) / sigma\n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "\n",
    "# Feature 2 - Binary\n",
    "for i in range(0, 1000):\n",
    "    if X[i,1] == 0:\n",
    "        tmp[i] = 1\n",
    "        tmp2[i] = 0\n",
    "    else:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 1\n",
    "        \n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp2.reshape(-1, 1)))\n",
    "\n",
    "# Feature 3 - Nominal\n",
    "for i in range(0, 1000):\n",
    "    if X[i,2] == 0:\n",
    "        tmp[i] = 1\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 0\n",
    "        tmp4[i] = 0\n",
    "    elif X[i,2] == 1:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 1\n",
    "        tmp3[i] = 0\n",
    "        tmp4[i] = 0\n",
    "    elif X[i, 2] == 2:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 1\n",
    "        tmp4[i] = 0\n",
    "    else:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 0\n",
    "        tmp4[i] = 1\n",
    "        \n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp2.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp3.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp4.reshape(-1, 1)))\n",
    "\n",
    "# Feature 4 - Numeric\n",
    "mean = np.mean(X[:,3], axis=0)\n",
    "sigma  = np.std(X[:,3], axis=0) \n",
    "tmp = (X[:,3] - mean) / sigma\n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "\n",
    "# Feature 5 - Numeric\n",
    "mean = np.mean(X[:,4], axis=0)\n",
    "sigma  = np.std(X[:,4], axis=0) \n",
    "tmp = (X[:,4] - mean) / sigma\n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "\n",
    "# Feature 6 - Binary\n",
    "for i in range(0, 1000):\n",
    "    if X[i,5] == 0:\n",
    "        tmp[i] = 1\n",
    "        tmp2[i] = 0\n",
    "    else:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 1\n",
    "        \n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp2.reshape(-1, 1)))\n",
    "\n",
    "# Feature 7 - Nominal\n",
    "for i in range(0, 1000):\n",
    "    if X[i,6] == 0:\n",
    "        tmp[i] = 1\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 0\n",
    "    elif X[i,6] == 1:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 1\n",
    "        tmp3[i] = 0\n",
    "    else:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 1\n",
    "        \n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp2.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp3.reshape(-1, 1)))\n",
    "\n",
    "# Feature 8 - Numeric\n",
    "mean = np.mean(X[:,7], axis=0)\n",
    "sigma  = np.std(X[:,7], axis=0) \n",
    "tmp = (X[:,7] - mean) / sigma\n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "\n",
    "# Feature 9 - Binary\n",
    "for i in range(0, 1000):\n",
    "    if X[i,8] == 0:\n",
    "        tmp[i] = 1\n",
    "        tmp2[i] = 0\n",
    "    else:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 1\n",
    "        \n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp2.reshape(-1, 1)))\n",
    "\n",
    "# Feature 10 - Numeric\n",
    "mean = np.mean(X[:,9], axis=0)\n",
    "sigma  = np.std(X[:,9], axis=0) \n",
    "tmp = (X[:,9] - mean) / sigma\n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "\n",
    "# Feature 11 - Nominal\n",
    "# Using four values because there are 0's in the dataset\n",
    "for i in range(0, 1000):\n",
    "    if X[i,10] == 0:\n",
    "        tmp[i] = 1\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 0\n",
    "        tmp4[i] = 0\n",
    "    elif X[i,10] == 1:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 1\n",
    "        tmp3[i] = 0\n",
    "        tmp4[i] = 0\n",
    "    elif X[i, 10] == 2:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 1\n",
    "        tmp4[i] = 0\n",
    "    else:\n",
    "        tmp[i] = 0\n",
    "        tmp2[i] = 0\n",
    "        tmp3[i] = 0\n",
    "        tmp4[i] = 1\n",
    "        \n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp2.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp3.reshape(-1, 1)))\n",
    "X_new = np.hstack((X_new, tmp4.reshape(-1, 1)))\n",
    "\n",
    "# Feature 12 - Numeric\n",
    "mean = np.mean(X[:,11], axis=0)\n",
    "sigma  = np.std(X[:,11], axis=0) \n",
    "tmp = (X[:,11] - mean) / sigma\n",
    "X_new = np.hstack((X_new, tmp.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's print out the first element of the new, processed variable, `X_new`, and its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X_new is:  [ 0.21046388  0.          1.          0.          0.          1.\n",
      "  0.          0.64283287 -2.35271743  1.          0.          0.\n",
      "  1.          0.          0.04456713  1.          0.          1.50724524\n",
      "  0.          0.          0.          1.          1.81967847]\n",
      "The shape of X_new is: (1000, 23)\n"
     ]
    }
   ],
   "source": [
    "# Printing the first element of X, and then printing the shape of X\n",
    "print ('The first element of X_new is: ', X_new[0])\n",
    "print ('The shape of X_new is: ' + str(X_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `X_new` represents the processed data from the dataset. The shape of `X_new` should be `1000, 23`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to split the dataset into three different sets. The first set is the training set. It will contain 60% of the examples (600 examples) and be used to train the models. The second set is the cross validation set that will contain 20% of the examples (200 examples). This set will be used in cross validation to compare the different models to see which performs best. The third set is the test set and will contain the remaining 20% of the examples (200 examples). The test set will be used to test the accuracy of the final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of indexes from 0 to 999\n",
    "arr = list(range(len(y)))\n",
    "\n",
    "# Calculate the lengths of each set \n",
    "data_len = len(arr)\n",
    "training_len = int(data_len * 0.6) # 60%\n",
    "cv_len = int(data_len * 0.2) # 20%\n",
    "# The test set will include the last 20%\n",
    "\n",
    "# Split the array of indices into different indices for each set\n",
    "train_indices = arr[:training_len]\n",
    "cv_indices = arr[training_len:training_len + cv_len]\n",
    "test_indices = arr[training_len + cv_len:]\n",
    "\n",
    "# Split the X and y into three different sets: training, cross validation, and testing\n",
    "X_train = np.array([X_new[i] for i in train_indices])\n",
    "y_train = np.array([y[i] for i in train_indices])\n",
    "\n",
    "X_cv = np.array([X_new[i] for i in cv_indices])\n",
    "y_cv = np.array([y[i] for i in cv_indices])\n",
    "\n",
    "X_test = np.array([X_new[i] for i in test_indices])\n",
    "y_test = np.array([y[i] for i in test_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see the shapes of the new sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (600, 23)\n",
      "The shape of y_train is: (600, 1)\n",
      "The shape of X_cv is: (200, 23)\n",
      "The shape of y_cv is: (200, 1)\n",
      "The shape of X_test is: (200, 23)\n",
      "The shape of y_test is: (200, 1)\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X_train is: ' + str(X_train.shape))\n",
    "print ('The shape of y_train is: ' + str(y_train.shape))\n",
    "print ('The shape of X_cv is: ' + str(X_cv.shape))\n",
    "print ('The shape of y_cv is: ' + str(y_cv.shape))\n",
    "print ('The shape of X_test is: ' + str(X_test.shape))\n",
    "print ('The shape of y_test is: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Model Selection and Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A neural network will be used as the model for this project. The input size is 23 units to match the number of features for each example. The output layer will have 1 unit to represent the output, either heart disease absent (0) or present (1). As for the hidden layers in the middle, three seperate architectures will be tested. One with one hidden layer, one with two, and one with three. A cross validation set will be used to test which model has the best accuracy.\n",
    "\n",
    "To determine an initial architecture, the regularization and learning rate constants will be 0.1 and 0.001 respectively.\n",
    "\n",
    "The activation for the hidden layers will be ReLu, or rectified linear unit. This is almost the same as a linear activation, but any value that is below 0 is set to 0.\n",
    "\n",
    "The output activation will be linear at first. Afterwards, the sigmoid function (shown below) will be applied.\n",
    "\n",
    "$$ g(z) = \\frac{1}{1+e^{-z}} $$\n",
    "\n",
    "g(z) will then be a value that is between 1 and 0. To interpret that output as a classification, a threshold, $\\kappa$, will be used. In this project, $\\kappa$ will equal 0.5.\n",
    "\n",
    "If g(z) $\\ge$ $\\kappa$, then prediction = 1. If g(z) < $\\kappa$, then prediction = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - One Hidden Layer\n",
    "\n",
    "The first architecture that will be tested is a neural network with 1 hidden layer that consists of 15 units.\n",
    "\n",
    "<img src=\"images/Model1.png\" style=\"width:400px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(23,)),   #specify input size\n",
    "        tf.keras.layers.Dense(15, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.1)),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ], name = \"my_model1\" \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compile the model and specify the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4977\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2294\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9956\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7908\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6123\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4542\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3157\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1922\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0831\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9867\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9023\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8280\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.7628\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7058\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6556\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6119\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5739\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5403\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5109\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4855\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4623\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4428\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4258\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4106\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3976\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3866\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3758\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3684\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3592\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3525\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3460\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3414\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3353\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3320\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3273\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3232\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3196\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3160\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3136\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3106\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3075\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3047\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3028\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3011\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2972\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2958\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2937\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2917\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2896\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2882\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2864\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2847\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2825\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2826\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2801\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2760\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2751\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2738\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2732\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2714\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2699\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2688\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2666\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2656\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2647\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2628\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2636\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2629\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2600\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2585\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2579\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2560\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2549\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2547\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2531\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2519\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2512\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2497\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2492\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2480\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2475\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2470\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2460\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2449\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2444\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2426\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2418\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2416\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2412\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2413\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2400\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2382\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2383\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2365\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2369\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2362\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2364\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2331\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x223a429d5e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model1.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will test the accuracy on the training and cross validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 96.166667\n",
      "CV Accuracy: 96.500000\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the training accuracy\n",
    "logit1train = model1(X_train)\n",
    "p1train = tf.nn.sigmoid(logit1train)\n",
    "trainAcc1 = np.mean((p1train>=0.5) == y_train) * 100\n",
    "print('Train Accuracy: %f'%trainAcc1)\n",
    "\n",
    "# Calculate and print the cross validation accuracy\n",
    "logit1cv = model1(X_cv)\n",
    "p1cv = tf.nn.sigmoid(logit1cv)\n",
    "cvAcc1 = np.mean((p1cv>=0.5) == y_cv) * 100\n",
    "print('CV Accuracy: %f'%cvAcc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Two Hidden Layers\n",
    "\n",
    "The second architecture that will be tested is a neural network with 2 hidden layers. The first will consist of 15 units and the second will consist of 10 units.\n",
    "\n",
    "<img src=\"images/Model2.png\" style=\"width:550px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(23,)),   #specify input size\n",
    "        tf.keras.layers.Dense(15, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.1)),\n",
    "        tf.keras.layers.Dense(10, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.1)),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ], name = \"my_model2\" \n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compile the model and specify the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.3885\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.0276\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.7089\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4299\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1838\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9657\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7738\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6035\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4543\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3234\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2083\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1082\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0202\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9441\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8774\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.8181\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7624\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7132\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6721\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6364\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6063\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5806\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5587\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5401\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5233\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5095\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4969\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4858\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4767\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4684\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4602\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4543\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4477\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4436\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4372\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4325\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4281\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4248\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4213\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4181\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4158\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4120\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4117\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4062\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4037\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4021\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3991\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3975\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3940\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3924\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3907\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3889\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3869\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3850\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3836\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3815\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3800\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3786\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3775\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3750\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3736\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3731\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3711\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3718\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3692\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3674\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3668\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3643\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3627\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3623\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3600\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3604\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3602\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3580\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3564\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3559\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3547\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3538\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3527\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3520\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3506\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3503\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3495\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3474\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3498\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3468\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3446\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3436\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3441\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3417\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3413\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3423\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3425\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3395\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3390\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3387\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3361\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3358\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3342\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x223a561bb20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model2.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will test the accuracy on the training and cross validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 95.833333\n",
      "CV Accuracy: 95.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the training accuracy\n",
    "logit2train = model2(X_train)\n",
    "p2train = tf.nn.sigmoid(logit2train)\n",
    "trainAcc2 = np.mean((p2train>=0.5) == y_train) * 100\n",
    "print('Train Accuracy: %f'%trainAcc2)\n",
    "\n",
    "# Calculate and print the cross validation accuracy\n",
    "logit2cv = model2(X_cv)\n",
    "p2cv = tf.nn.sigmoid(logit2cv)\n",
    "cvAcc2 = np.mean((p2cv>=0.5) == y_cv) * 100\n",
    "print('CV Accuracy: %f'%cvAcc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Three Hidden Layers\n",
    "\n",
    "The third architecture that will be tested is a neural network with 3 hidden layers. The first will consist of 15 units, the second will have 10 units, and the third will have 5 units.\n",
    "\n",
    "<img src=\"images/Model3.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential(\n",
    "    [               \n",
    "        tf.keras.Input(shape=(23,)),   #specify input size\n",
    "        tf.keras.layers.Dense(15, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.1)),\n",
    "        tf.keras.layers.Dense(10, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.1)),\n",
    "        tf.keras.layers.Dense(5, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.1)),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "    ], name = \"my_model3\" \n",
    ")                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will compile the model and specify the loss function and the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 4.0351\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.6294\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 3.2698\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.9518\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.6699\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4205\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1994\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0012\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8237\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6637\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.5230\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4001\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2929\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1989\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1172\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0457\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9830\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9285\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8805\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8379\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8006\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7680\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7391\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7132\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6896\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6690\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6510\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6335\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6190\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6056\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5934\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5828\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5732\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5639\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5568\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5483\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5419\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5364\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5299\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5250\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5197\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5157\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5113\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5075\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5040\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5008\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4975\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4946\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4926\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4896\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4860\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4848\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4835\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4794\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4762\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4759\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4738\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4710\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4697\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4666\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4654\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4641\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4618\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4602\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4581\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4565\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4557\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4542\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4526\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4524\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4503\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4496\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4482\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4457\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4445\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4428\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4425\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4408\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4400\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4387\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4382\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4374\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4375\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4353\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4335\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4351\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4331\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4301\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4297\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4292\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4283\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4273\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4262\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4269\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4238\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4236\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4245\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4222\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4216\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x223a68c0cd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "model3.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will test the accuracy on the training and cross validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 95.500000\n",
      "CV Accuracy: 94.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the training accuracy\n",
    "logit3train = model3(X_train)\n",
    "p3train = tf.nn.sigmoid(logit3train)\n",
    "trainAcc3 = np.mean((p3train>=0.5) == y_train) * 100\n",
    "print('Train Accuracy: %f'%trainAcc3)\n",
    "\n",
    "# Calculate and print the cross validation accuracy\n",
    "logit3cv = model3(X_cv)\n",
    "p3cv = tf.nn.sigmoid(logit3cv)\n",
    "cvAcc3 = np.mean((p3cv>=0.5) == y_cv) * 100\n",
    "print('CV Accuracy: %f'%cvAcc3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 - Comparing the Architectures\n",
    "\n",
    "When running the code, these are the results that I got. I tried to make a fancy plot that would graph the current values, but matplot kept killing my terminal.\n",
    "\n",
    "| # of Hidden Layers | Training Accuracy | CV Accuracy |\n",
    "|--------------------|-------------------|-------------|\n",
    "| 1 Hidden Layer     | 96.1667           | 96.00       |\n",
    "| 2 Hidden Layers    | 96.00             | 95.00       |\n",
    "| 3 Hidden Layers    | 95.166            | 95.00       |\n",
    "\n",
    "Surpisingly, the architecture with only 1 hidden layer performed the best in both training accuracy and cross validation accuracy. There likely was not enough data in the training set to fine tune the parameters in the larger neural networks. However, all of these accuracies are acceptable, so it does not seem like a bug."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Regularization and Parameter Tuning\n",
    "\n",
    "Now that the architecture has been decided, we are going to fine tune the regularization parameter. The learning rate is Adam optimization algorithm alters the learning rate between each epoch depending on the change in the loss function values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization Tuning\n",
    "\n",
    "This code below will test different regularization parameter values and then output the training and cross validation accuracies for each. Note: plotting is not used because matplot keeps killing my terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.5434\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2651\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0248\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8177\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6378\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4804\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3420\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2192\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1095\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0097\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9203\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8389\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7668\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7039\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6489\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6023\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5625\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5284\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4996\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4750\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4537\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4355\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4198\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4061\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3948\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3837\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3753\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3666\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3597\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3536\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3487\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3430\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3387\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3340\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3305\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3271\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3233\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3207\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3178\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3149\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3128\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3100\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3073\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3053\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3035\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3012\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2995\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2973\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2955\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2937\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2918\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2902\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2886\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2873\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2853\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2840\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2826\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2807\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2810\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2792\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2772\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2758\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2746\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2736\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2722\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2715\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2699\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2698\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2676\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2667\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2658\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2656\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2661\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2636\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2605\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2600\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2586\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2561\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2561\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2546\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2549\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2534\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2514\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2525\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2518\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2497\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2485\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2483\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2476\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2459\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2465\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2449\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2446\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2437\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2425\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2414\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2410\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2408\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4928\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2098\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9713\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7690\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.5929\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4412\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3084\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1915\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0888\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9969\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9161\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8439\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7801\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7245\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6749\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6319\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5940\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5607\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5312\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5052\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4823\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4626\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4454\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4301\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4174\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4052\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3955\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3859\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3780\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3710\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3651\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3585\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3532\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3475\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3430\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3387\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3343\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3311\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3276\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3243\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3218\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3186\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3157\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3134\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3111\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3086\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3067\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3042\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3023\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3002\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2981\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2963\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2945\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2930\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2907\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2893\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2876\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2855\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2838\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2815\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2799\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2786\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2774\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2759\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2749\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2732\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2728\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2705\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2695\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2684\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2681\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2686\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2660\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2660\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2626\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2620\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2605\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2591\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2576\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2575\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2559\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2561\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2545\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2525\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2535\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2528\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2493\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2490\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2483\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2465\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2471\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2453\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2450\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2440\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2427\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2415\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2411\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2408\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4569\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1991\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9731\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7774\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6042\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4521\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3171\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1967\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0892\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9918\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9065\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8312\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7647\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7072\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6554\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6110\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5719\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5373\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5076\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4814\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4583\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4382\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4213\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4061\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3936\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3813\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3719\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3621\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3541\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3471\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3415\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3350\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3301\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3249\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3210\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3173\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3132\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3105\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3074\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3043\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3023\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2993\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2966\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2946\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2927\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2904\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2886\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2865\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2846\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2829\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2779\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2766\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2745\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2733\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2720\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2699\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2705\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2689\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2667\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2653\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2642\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2632\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2619\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2612\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2596\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2595\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2573\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2566\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2556\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2556\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2565\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2539\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2540\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2500\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2486\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2474\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2460\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2460\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2446\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2449\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2433\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2414\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2426\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2420\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2398\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2386\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2386\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2379\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2369\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2352\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2350\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2341\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2329\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2316\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2314\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2312\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 2.5699\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2937\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0585\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8559\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 1.6810\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.5267\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3909\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2700\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1623\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0651\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9790\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9011\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8323\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7713\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7167\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6681\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6249\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5862\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5523\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5229\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4973\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4750\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4558\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4388\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4246\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4110\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4004\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3897\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3809\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3733\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3669\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3600\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3546\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3489\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3444\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3402\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3358\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3326\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3291\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3256\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3231\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3198\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3168\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3144\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3122\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3096\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3076\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3052\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3032\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3011\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2990\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2971\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2953\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2939\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2915\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2901\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2885\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2864\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2864\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2845\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2823\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2809\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2795\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2783\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2769\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2760\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2742\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2740\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2717\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2707\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2696\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2692\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2698\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2672\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2672\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2639\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2632\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2618\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2605\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2590\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2589\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2560\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2540\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2550\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2542\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2521\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2508\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2506\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2499\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2481\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2486\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2469\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2466\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2457\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2444\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2432\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2428\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2426\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.3810\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.1317\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9145\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7258\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 1.5591\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4132\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2827\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1659\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0615\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9668\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8826\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8073\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7412\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6842\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6334\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5900\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5522\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5197\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4915\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4672\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4463\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4283\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4128\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3992\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3881\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3771\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3689\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3604\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3536\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3477\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3430\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3374\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3332\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3287\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3254\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3221\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3185\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3161\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3133\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3104\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3085\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3056\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3030\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3011\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2993\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2970\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2954\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2933\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2915\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2898\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2879\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2864\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2848\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2836\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2815\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2803\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2789\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2769\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2773\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2757\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2736\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2722\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2710\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2700\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2686\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2679\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2663\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2662\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2640\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2632\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2622\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2620\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2628\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2602\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2602\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2569\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2564\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2550\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2537\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2523\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2523\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2508\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2511\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2495\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2476\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2487\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2480\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2459\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2447\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2445\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2439\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2420\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2428\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2411\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2408\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2399\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2387\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2374\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2372\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2369\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.4646\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.2095\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.9836\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.7843\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6088\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4539\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3163\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1944\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0868\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9911\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9073\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8324\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7663\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7085\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6562\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6096\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5680\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5302\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4970\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4685\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4437\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4223\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4041\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3881\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3755\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3626\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3534\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3434\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3357\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3292\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3239\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3177\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3130\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3084\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3043\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3012\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2971\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2947\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2920\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2887\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2871\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2841\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2814\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2796\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2778\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2756\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2740\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2720\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2703\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2685\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2669\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2653\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2637\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2627\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2606\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2596\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2583\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2562\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2570\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2556\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2535\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2520\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2509\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2498\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2488\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2483\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2465\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2470\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2443\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2439\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2429\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2427\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2447\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2420\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2415\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2390\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2375\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2364\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2348\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2335\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2336\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2326\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2327\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2312\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2292\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2308\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2301\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2283\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2266\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2269\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2262\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2244\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2254\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2237\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2236\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2226\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2215\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2201\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2202\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2199\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 2ms/step - loss: 2.5717\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.3010\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 2.0672\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.8630\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.6821\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.5223\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 2ms/step - loss: 1.3802\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2526\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1383\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0344\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9422\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8586\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7840\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7184\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6595\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6090\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5652\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5276\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4953\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4675\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4434\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4225\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4049\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3891\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3763\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3638\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3544\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3448\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3373\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3309\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3260\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3199\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3157\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3111\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3077\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3045\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3008\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2985\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2958\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2930\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2913\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2886\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2861\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2843\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2827\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2805\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2791\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2772\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2756\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2741\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2725\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2710\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2696\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2686\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2666\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2656\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2644\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2625\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2632\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2618\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2597\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2583\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2574\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2565\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2553\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2548\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2532\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2533\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2510\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2505\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2496\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2496\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2507\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2481\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2482\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2450\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2444\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2431\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2419\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2406\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2407\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2394\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2398\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2383\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2377\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2371\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2351\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2338\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2339\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2333\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2315\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2324\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2307\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2306\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2297\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2286\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2274\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2272\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2271\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0.0, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3]\n",
    "models=[None] * len(lambdas)\n",
    "for i in range(len(lambdas)):\n",
    "    lambda_ = lambdas[i]\n",
    "    models[i] =  Sequential(\n",
    "        [\n",
    "        tf.keras.Input(shape=(23,)),   #specify input size\n",
    "        tf.keras.layers.Dense(15, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.1)),\n",
    "        tf.keras.layers.Dense(1, activation='linear')\n",
    "        ]\n",
    "    )\n",
    "    models[i].compile(\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    )\n",
    "\n",
    "    models[i].fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Decision\n",
    "\n",
    "This code will print out the training and cross valudation accuracies for the prior test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda = 0.0\n",
      "Train Accuracy: 96.166667\n",
      "CV Accuracy: 95.500000\n",
      "\n",
      "\n",
      "Lambda = 0.001\n",
      "Train Accuracy: 96.166667\n",
      "CV Accuracy: 96.000000\n",
      "\n",
      "\n",
      "Lambda = 0.01\n",
      "Train Accuracy: 96.166667\n",
      "CV Accuracy: 96.500000\n",
      "\n",
      "\n",
      "Lambda = 0.05\n",
      "Train Accuracy: 96.166667\n",
      "CV Accuracy: 96.000000\n",
      "\n",
      "\n",
      "Lambda = 0.1\n",
      "Train Accuracy: 96.166667\n",
      "CV Accuracy: 96.500000\n",
      "\n",
      "\n",
      "Lambda = 0.2\n",
      "Train Accuracy: 96.333333\n",
      "CV Accuracy: 97.000000\n",
      "\n",
      "\n",
      "Lambda = 0.3\n",
      "Train Accuracy: 96.166667\n",
      "CV Accuracy: 96.500000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lambdas)):\n",
    "    lambda_ = lambdas[i]\n",
    "    print(f\"Lambda = {lambda_}\")\n",
    "    # Calculate and print the training accuracy\n",
    "    logitTrain = models[i](X_train)\n",
    "    pTrain = tf.nn.sigmoid(logitTrain)\n",
    "    trainAcc = np.mean((pTrain>=0.5) == y_train) * 100\n",
    "    print('Train Accuracy: %f'%trainAcc)\n",
    "\n",
    "    # Calculate and print the cross validation accuracy\n",
    "    logitCV = models[i](X_cv)\n",
    "    pCV = tf.nn.sigmoid(logitCV)\n",
    "    cvAcc = np.mean((pCV>=0.5) == y_cv) * 100\n",
    "    print('CV Accuracy: %f'%cvAcc)\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the results that I achieved. The difference is the magnitude of the difference between the training accuracy and the cross validation accuracy.\n",
    "\n",
    "| Lambda | Training Accuracy | CV Accuracy | Difference |\n",
    "|--------|-------------------|-------------|------------|\n",
    "| 0.0    | 96.1667           | 95.5        | 0.667      |\n",
    "| 0.001  | 96.1667           | 96.0        | 0.1667     |\n",
    "| 0.01   | 96.1667           | 96.5        | 0.33       |\n",
    "| 0.05   | 96.1667           | 96.0        | 0.1667     | \n",
    "| 0.1    | 96.1667           | 96.5        | 0.33       |\n",
    "| 0.2    | 96.33             | 97.0        | 0.667      |\n",
    "| 0.3    | 96.1667           | 96.5        | 0.33       |\n",
    "\n",
    "The lambda values with the smallest difference appears to be 0.001 and 0.05. I chose lambda = 0.05 for the regularization parameter because having a larger regularization parameter will reduce the chances that the model is overfitting.\n",
    "\n",
    "$$ \\lambda = 0.05$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Evaluation\n",
    "\n",
    "First, let's build a fresh model with the decided architecture and regularization parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 - Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 1.5887\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.4229\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.2847\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.1644\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 1.0600\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.9665\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8841\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.8112\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.7471\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6891\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.6395\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5951\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5562\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.5228\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4921\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4653\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4413\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4200\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.4012\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3846\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3697\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3562\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3445\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3338\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3249\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3152\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3082\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.3002\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2939\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2882\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2836\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2781\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2739\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2696\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2660\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2629\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2592\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2570\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2542\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2515\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2499\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2471\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2447\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2430\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2414\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2394\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2380\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2363\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2349\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2334\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2319\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2305\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2292\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2282\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2263\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2254\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2244\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2225\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2233\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2220\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2200\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2188\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2179\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2168\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.2160\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2154\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2139\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2142\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2121\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2114\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2107\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2103\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2120\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2094\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2093\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2063\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2057\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2046\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2034\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2022\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 1ms/step - loss: 0.2020\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2014\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2016\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.2000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1984\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1996\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1987\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1974\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1960\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1962\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1955\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1938\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1946\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1932\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1930\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1922\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1911\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1900\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1899\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 2ms/step - loss: 0.1895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x223a92be070>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalModel =  Sequential(\n",
    "    [\n",
    "    tf.keras.Input(shape=(23,)),   #specify input size\n",
    "    tf.keras.layers.Dense(15, activation='relu', kernel_regularizer = tf.keras.regularizers.l2(0.05)),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "    ]\n",
    ")\n",
    "\n",
    "finalModel.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits = True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")\n",
    "\n",
    "finalModel.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Calculate Testing Accuracy\n",
    "\n",
    "Now, let's the accuracy using the test set that was created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.000000\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the testing accuracy\n",
    "logitTest = finalModel(X_test)\n",
    "pTest = tf.nn.sigmoid(logitTest)\n",
    "testAcc = np.mean((pTest>=0.5) == y_test) * 100\n",
    "print('Test Accuracy: %f'%testAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I ran the code, I had a test accuracy of 95.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 - Calculate Precision, Recall, and F1 Score\n",
    "\n",
    "To gain a better understanding of the accuracy of the model, we are going to calculate the precision, recall, and F1 score.\n",
    "\n",
    "The precision will tell us what fraction of the patients we predicted actually have heart disease. True positives indicate the number of examples that were predicted positive and were actually positive. Predicted Positives is the total number of positive predictions from the model.\n",
    "$$ precision = \\frac{True Positives}{Predicted Positives} $$\n",
    "\n",
    "The recall will tell us what fraction of the patients that had heart disease were number predicted correctly. Actual Positives refer to the total number of patients that has heart disease in the dataset.\n",
    "$$ recall = \\frac{True Positives}{Actual Positives} $$\n",
    "\n",
    "The F1 score, also known as the harmonic mean, is a good way to compare precision and recall numbers.\n",
    "$$ F1 = \\frac{2*precision*recall}{precision + recall} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.975207\n",
      "Recall: 0.959350\n",
      "F1 Score: 0.967213\n"
     ]
    }
   ],
   "source": [
    "predictedPositives = 0\n",
    "actualPositives = 0\n",
    "truePositives = 0\n",
    "\n",
    "for i in range(0, len(y_test)):\n",
    "    prediction = float(pTest[i] >= 0.5)\n",
    "    if y_test[i] == 1:\n",
    "        actualPositives += 1\n",
    "    if prediction == 1:\n",
    "        predictedPositives += 1\n",
    "    if y_test[i] == prediction and prediction == 1:\n",
    "        truePositives += 1\n",
    "    \n",
    "precision = truePositives / predictedPositives\n",
    "recall = truePositives / actualPositives\n",
    "F1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print('Precision: %f'%precision)\n",
    "print('Recall: %f'%recall)\n",
    "print('F1 Score: %f'%F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "When running the code, I got the following values:  \n",
    "Precision: 0.967213  \n",
    "Recall: 0.959350  \n",
    "F1 Score: 0.963265  \n",
    "\n",
    "This model has a great F1 score. The precision and recall were fairly close too which means that the threshold appears to be set correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Analysis\n",
    "\n",
    "Overall, the model that was chosen worked great on the dataset. Much work was needed to process the data. Z-score normalization or one-hot encoding needed to be applied to each feature in the dataset seperately, depending on categorization of the data. Then, a neural network architecture was decided: 23 inputs for the processed data's features, one hidden layer with 15 units, and an output layer with 1 unit. After an architecure was decided, a "
   ]
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "Python [conda env:my_tf_env]",
   "language": "python",
   "name": "conda-env-my_tf_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
